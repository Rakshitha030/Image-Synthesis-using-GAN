# Image-Synthesis-using-GAN
This project (NovaGAN) is a smart, all-in-one diffusion-based image & video generation app built using PyTorch + Hugging Face Diffusers + Gradio.

What it does:

ðŸ“¸ Takes an input image

âœï¸ Reads a prompt (optional)

ðŸ§  Automatically decides which model to use:

Instruct-Pix2Pix â†’ for editing images using text instructions

ControlNet â†’ for structure-aware generation (Canny, Depth, HED, Scribble, MLSD)

Image-to-Video â†’ if no prompt is given, converts an image into a short video

âš™ï¸ Applies image preprocessing + enhancement

ðŸŒ Launches a modern Gradio web UI with image & video tabs

Key highlights:

Auto model detection (no manual switching)

Automatic ControlNet variant classification

GPU-optimized (FP16, autocast, CPU offload)

Clean, dark, vibrant UI

Outputs both images and videos

```mermaid
flowchart TD
  A --> B

